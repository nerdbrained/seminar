<!DOCTYPE html>
<html><head><meta charset="utf-8" /><meta name="google-site-verification" content="NaytRH7PCHM8SH9XV-xgMLEi_1m1wS9lPBAIvTJ-wvs" /><meta name="viewport" content="width=device-width, initial-scale=1" /><link href="//yegor256.github.io/tacit/tacit.min.css" rel="stylesheet" /><link href="/css/custom.css" rel="stylesheet" /><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-93527069-1', 'auto');
ga('send', 'pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    jax: [
        "input/TeX",
        "input/MathML",
        "input/AsciiMath",
        "output/CommonHTML"
    ],
    extensions: [
        "tex2jax.js",
        "mml2jax.js",
        "asciimath2jax.js",
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js"
    ],
    TeX: {
        extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js"
        ]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": {
        availableFonts: ["TeX"]
    }
});
</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script><title>Game Theory (Part 1)</title></head><body><nav><input id="nav-trigger" type="checkbox" class="nav-trigger" checked="checked" /><ul><li><a href="/"><img src="/images/logo.png" height="64" title="Home" alt="Home" width="64" /></a></li><li><a href="/archive">archive</a></li><li><a href="/tags">tags</a></li><li><a href="/faq">faq</a></li><li><a href="/document">library</a></li><li><a href="/potential-topics">topics</a></li></ul><label for="nav-trigger"></label></nav><section><article><p>This talk on Game Theory (Part 1) was held on Friday November 4, 2016 in MC 4020. The speaker was Koosha Totonchi.</p><h2>Abstract</h2><div><p>A game is a “mathematical model between interacting decision makers” where each player must make choices based on a set of rules. Every individual in a game must also have a preferred reaction to any combination of actions taken by other agents.  Game theory is about the study and application of these models. It involves various solution concepts and methods that can be employed to predict the outcomes of strategic engagements.  This talk will introduce the major ideas in the field. There will be a focus on basic definitions, types of games, and how we can “solve games” using the Nash equilibrium. Hopefully we’ll get to “play” some ourselves. Towards the end, we can also review some neat unsolved problems in game theory that are very easy to understand, but prove really difficult to solve. </p></div><h2>Summary</h2><div><h3>Description</h3><p>A game is a mathematical model between interacting decision makers, where each player must make choices based on a set of rules. Every individual in a game must also have a preferred reaction to any combination of actions taken by other agents.</p><p>Game theory is about the study and application of these models. It involves various solution concepts and methods that can be employed to predict the outcomes of strategic engagements.</p><p>This talk will introduce the major ideas in the field. There will be a focus on basic definitions, types of games, and how we can “solve games” using the Nash equilibrium. Hopefully we’ll get to “play” some ourselves. Towards the end, we can also review some neat unsolved problems in game theory that are very easy to understand, but prove difficult to solve.</p><h3>Walkthrough</h3><ul><li><p>Initial auction</p></li><li><p>What is a game? (See page 2)</p></li><li><p>What are the types of games which can be played?</p><ul><li><p>Games can have perfect or imperfect information, be symmetric or asymmetric, sequential or simultaneous, zero or non-zero sum, co-operative or non-co-operative.</p></li></ul></li><li><p>What kinds of strategies can be employed? (See page 2-3)</p><ul><li><p>Strategies can be mixed and pure, or just pure in form</p></li></ul></li><li><p>How do you “solve” a game mathematically?</p><ul><li><p>Nash equilibrium: history, how it was derived, and meaning (See page 2, 4)</p></li><li><p>Minimax theorem</p></li><li><p>Best response functions (See page 2, 4)</p></li><li><p>Comparing strictly and weakly dominated actions (See page 2, 4)</p></li><li><p>Further tips on calculating Nash equilibrium (See page 5-6)</p></li></ul></li><li><p>Unsolved problems:</p><ul><li><p>Rendezvous on a line</p></li></ul></li></ul><h3>Interesting Results</h3><p><a href="http://www.cs.ubc.ca/~jiang/papers/NashReport.pdf">A Tutorial on the Proof of the Existence of Nash Equilibria</a></p><h3>Interesting Applications</h3><ul><li><p><a href="http://www.economist.com/node/21527025">Game Theory in Practice</a></p></li><li><p><a href="http://www.wbiconpro.com/244-Lim.pdf">Airline Pricing Strategy 1</a></p></li><li><p><a href="http://link.springer.com/article/10.1057/rpm.2008.30">Airline Pricing Strategy 2</a></p></li><li><p><a href="https://www.cs.cornell.edu/home/kleinber/networks-book/networks-book-ch09.pdf">Optimization of Auctions (Theory)</a></p></li><li><p><a href="http://www.sciencedirect.com/science/article/pii/S0014292196000177">Optimization of Auctions (Application)</a></p></li><li><p><a href="http://www.ssc.wisc.edu/~dquint/econ698/lecture%202.pdf">Arrows Impossibility Theorem (Introduction)</a></p></li><li><p><a href="http://www.math.cornell.edu/twiki/pub/SMI/SocialChoice/JohnGArrow.pdf">Three Brief Proofs of Arrow’s Impossibility Theorem</a></p></li><li><p><a href="http://www.cs.cornell.edu/home/kleinber/networks-book/networks-book-ch08.pdf">Modeling Network Traffic using Game Theory</a></p></li><li><p><a href="https://www.cs.cornell.edu/home/halpern/papers/csgt.pdf">Computer Science and Game Theory: A Brief Survey</a></p></li><li><p><a href="https://www.youtube.com/watch?v=L7XiE_V0PZ8&amp;list=PL8F6C117EDAE9EF2E">A Theory of StarCraft</a></p></li><li><p><a href="http://pricetheory.uchicago.edu/levitt/Papers/ChiapporiGrosecloseLevitt2002.pdf">Soccer Penalty Kicks</a></p></li></ul><h3>Game Theory Notes</h3><p>A game with ordinal preferences is a <em>tuple</em> or <em>list</em> (players, actions, preferences)</p><p>Players are a set <span>$N = \{ 1, 2, 3,4\ldots n\}$</span></p><p>Actions are a set of <span>$\text{m}$</span> choices available to each player <span>$i$</span> in <span>$N$</span>. This gives us:</p><div>\[A_{i} = \{ a_{i}^{1},a_{i}^{2},a_{i}^{3}\ldots a_{i}^{m}\}\]</div><p>Note, not all players have to have the same number of choices available to them.</p><p>Let <span>$A = A_{1} \times A_{2} \times \ldots  \times A_{n}$</span> be the set of possible combinations of pure strategies among all players.</p><p>Action profiles are a set composed of the actions each player has chosen for the game. The action profile can be written as follows: <span>$a = \{ a_{1}, a_{2}, a_{3}\ldots a_{n}\}$</span> indexed by <span>$i$</span> where <span>$i$</span> is part of the player set.</p><p>Preferences for each player are given by a “payoff” function, defined on the set of actions each player has chosen to play (the action profile) to the real numbers. In other words:</p><div>\[\text{Player }i^{'}s\text{ Preferences} =
u_{i}:\left( a_{1},a_{2},a_{3}\ldots a_{n} \right)\mathbb{\rightarrow R}
\text{ or }u_{i}:(a\mathbb{) \rightarrow R}\]</div><p>A game is symmetric if the payoffs depend only on the strategies employed, not on who is playing them. For example, Prisoner’s Dilemma is symmetric.</p><p>A Nash equilibrium is a situation in a game where:</p><div>\[u_{i}\left( a_{1}^{*}\ldots{a_{i}^{*}\ldots a}_{n}^{*} \right) \geq
u_{i}\left( a_{1}^{*}\ldots a_{i}^{}\ldots a_{n}^{*} \right)
\forall a_{i} \in A_{i}\text{, and }\forall\text{ players }i\]</div><p>Using another notation, where <span>$a_{- i}^{*}$</span> represents the actions that all other players <span>$\neq i$</span> have chosen,</p><div>\[u_{i}\left( a_{i}^{*},a_{- i}^{*} \right) \geq u_{i}\left( a_{i}^{},
a_{- i}^{*} \right)
\forall a_{i} \in A_{i}\text{, and }\forall\text{ players }i\]</div><p>Strict &amp; non-strict Nash equilibrium:</p><div>\[\text{Strict} = u_{i}\left( a_{i}^{*},a_{- i}^{*} \right) &gt;
u_{i}\left( a_{i}^{},a_{- i}^{*} \right)
\forall a_{i} \in A_{i}\text{, and }\forall\text{ players }i\]</div><div>\[\text{Non-strict} = u_{i}\left( a_{i}^{*},a_{- i}^{*} \right)
\geq u_{i}\left( a_{i}^{},a_{- i}^{*} \right)
\forall a_{i} \in A_{i}\text{, and }\forall\text{ players }i\]</div><p>Strictly dominated strategies:</p><p>An action<span>$a_{i}$</span> is strictly dominated if there is another action <span>$a_{i}^{*}$</span> which results in a higher payoff for player <span>$i$</span> through all the possible combinations of other players’ actions:</p><div>\[u\left( a_{i}^{*},a_{- i} \right) &gt; u\left( a_{i}^{},a_{- i} \right)
\forall\text{ possible }a_{-i}\]</div><p>Strictly dominated strategies are not played in a Nash equilibrium, so they can be removed from the game when looking for such points.</p><p>Weakly dominated strategies:</p><p>An action <span>$a_{i}$</span> is said to be weakly dominated if one can <em>sometimes</em> improve by changing to another strategy <span>$a_{i}^{*}:$</span></p><div>\[n{u\left( a_{i}^{*},a_{- i} \right) \geq u\left( a_{i}^{},a_{- i}
\right)\forall\text{possible}a_{- i}\&amp;\exists a_{- i}\text{ such that }
u \left(a_{i}^{*},a_{- i} \right) &gt; u\left( a_{i}^{},a_{- i} \right)}\]</div><p>Best response functions:</p><p>The best response function is a set valued function that takes actions which all other players have chosen for the game and returns the best possible set of responses for player <span>$\text{i}$</span> In a Nash equilibrium, everyone plays a best response.</p><p>A game with von Neumann-Morgenstern (vNM) preferences is a <em>tuple</em> or <em>list</em> (players, actions, preferences)</p><p>Players are a set <span>$N = \{ 1,2,3,4\ldots n\}$</span></p><p>Actions are a set of <span>$\text{m}$</span>choices available to each player <span>$i$</span> in <span>$\text{N.}$</span>This gives us:<span>$A_{i} = \{ a_{i}^{1},a_{i}^{2},a_{i}^{3}\ldots a_{i}^{m}\}$</span>. Note, not all players have to have the same number of choices available to them.</p><p>Let <span>$A = A_{1} \times A_{2} \times \ldots \times A_{n}$</span> be the set of possible combinations of pure strategies among all players.</p><p>A mixed strategy is a probability distribution over the set of actions available to player <span>$i$</span>. In other words, a mixed strategy is a vector of real numbers for player <span>$i$</span> in <span>$N$</span>, satisfying the property that each element is in the real numbers and between zero and one. That is, element <span>$x_{i}^{k}$</span> in mixed strategy vector <span>$x_{i}$</span> for player <span>$\text{i}$</span>satisfies <span>$x_{i}^{k} \in R,\ 0 \leq x_{i}^{k} \leq 1,\forall k$</span>. The number of elements in this vector is equal to the number of actions in player <span>$i$</span>’s set of available actions. Thus, the vector looks as follows: <span>$x_{i} = (x_{i}^{1}$</span>, <span>$x_{i}^{2},x_{i}^{3}\ldots x_{i}^{m})$</span>, where each probability <span>$x_{i}^{m}$</span> is the chance out of 1 that the player <span>$i$</span> will select a corresponding action <span>$a_{i}^{m}$</span>. Alternatively, this can be written as follows: <span>$x_{i} = ( x_{i}^{}(a_{i}^{1})$</span>,<span>$x_{i}^{}\left( a_{i}^{2} \right),x_{i}^{}\left( a_{i}^{3} \right)\ldots x_{i}^{}\left( a_{i}^{m} \right))$</span>, where <span>$x_{i}\left( a_{i}^{m} \right)$</span> is the probability of player <span>$i$</span> selecting action <span>$a_{i}^{m}$</span>.</p><p>Let <span>$X_{i}$</span> denote the set of possible mixed strategies for player <span>$i$</span>. Then let<span>$X = X_{1} \times X_{2} \times \ldots \times X_{n}$</span> denote the set of all possible combinations of mixed strategies among all players.</p><p>Preferences for each player involve two parts. The first part involves a simple “payoff” function (the same kind we had for a regular game with pure strategies), defined on the set of given actions for each player to the real numbers. In other words:</p><div>\[u_{i}:\left( a_{1},a_{2},a_{3}\ldots a_{n} \right)\mathbb{\rightarrow R}\text{or}u_{i}:(a\mathbb{) \rightarrow R}\]</div><p>The second involves the probability of that result occurring, given by the probability that player one selects action <span>$a_{1},$</span> and player two selects action <span>$a_{2}$</span>, and so on, up to player <span>$n$</span> selecting action <span>$a_{n}$</span>. This can just be calculated by a product: <span>$\left( \text{x}_{1}^{}\left( a_{1} \right)*x_{2}^{}\left( a_{2} \right)*x_{3}^{}\left( a_{3} \right)*\ldots*x_{n}^{}\left( a_{n} \right) \right)$</span>. This product multiplied by the payoff of the actual actions is an expected value.</p><div>\[\left( \text{x}_{1}^{}\left( a_{1} \right)*x_{2}^{}\left( a_{2} \right)*x_{3}^{}\left( a_{3} \right)*\ldots*x_{n}^{}\left( a_{n} \right) \right)*u_{i}:(a_{1},a_{2},a_{3}\ldots a_{n})\]</div><p>Calculating this over every single possible combination of actions and summing them all gives us the expected payoff of player <span>$\text{i}$</span>under a mixed strategy profile. Note that we assume players make their choices independently. Let <span>$x = \left( \text{x}_{1}^{}\left( a_{1} \right)*x_{2}^{}\left( a_{2} \right)*x_{3}^{}\left( a_{3} \right)*\ldots*x_{n}^{}\left( a_{n} \right) \right)$</span>. Let <span>$c = \left( a_{1},a_{2},\ldots,a_{n} \right) \in A$</span> be some given combination of pure strategies. Then you have:</p><div>\[x\left( c \right) = \prod_{j = 1}^{n}{x_{j}^{}\left( a_{j} \right)}\]</div><p>Where <span>$a_{j}$</span> is just some action for player <span>$j$</span> in the combination of pure strategies <span>$c$</span>. Then:</p><div>\[U_{i}\left( x \right) = \sum_{c \in A}^{}{x(c)*u_{i}(c)}\]</div><p>A mixed strategy Nash equilibrium is a situation in a vNM game where:</p><div>\[U_{i}\left( x_{1}^{*}*\ldots*x_{i}^{*}*\ldots*x_{n}^{*} \right) \geq U_{i}\left( x_{1}^{*}*\ldots*x_{i}^{}*\ldots*x_{n}^{*} \right)
\forall x_{i} \in X_{i}\text{ , and }\forall\text{ players }i\]</div><p>Using another notation:</p><div>\[U_{i}\left( x_{i}^{*},x_{- i}^{*} \right) \geq U_{i}\left( x_{i}^{},x_{- i}^{*} \right)
\forall x_{i} \in X_{i}\text{ , and }\forall\text{ players }i\]</div><p>Strict &amp; non-strict mixed strategy Nash equilibrium:</p><div>\[\text{Strict} = U_{i}\left( x_{i}^{*},x_{- i}^{*} \right) &gt; U_{i}\left( x_{i}^{},x_{- i}^{*} \right)
\forall x_{i} \in X_{i}\text{ , and }\forall\text{ players }i\]</div><div>\[\text{Non-strict} = U_{i}\left( x_{i}^{*},x_{- i}^{*} \right) \geq U_{i}\left( x_{i}^{},x_{- i}^{*} \right)
\forall x_{i} \in X_{i}\text{ , and }\forall\text{ players }i\]</div><p>A nondegenerate mixed strategy Nash equilibrium (a mixed strategy Nash equilibrium that is not also a pure strategy Nash equilibrium) is never strict: every player whose mixed strategy assigns positive probability to more than one action is indifferent between her equilibrium mixed strategy and every action to which this mixed strategy assigns positive probability.</p><p>Strictly dominated strategies:</p><p>In a strategic game with vNM preferences, player <span>$i$</span>’s mixed strategy <span>$x_{i}$</span> strictly dominates his/her pure non-mixed action <span>$a_{i}$</span> if <span>$U_{i} (x_{i},a_{- i}) &gt; u_{i}(a_{i},a_{- i})$</span> for every list <span>$a_{- i}$</span> of the other players’ pure actions. In a Nash equilibrium of a strategic game with ordinal preferences no player uses a strictly dominated action. The same is true in a mixed strategy equilibrium. Also, a strictly dominated action is not used with positive probability in any mixed strategy equilibrium.</p><p>Weakly dominated strategies:</p><p>In a strategic game with vNM preferences, player <span>$i$</span>’s mixed strategy <span>$x_{i}$</span> weakly dominates his/her action <span>$a_{i}$</span> if <span>$U_{i}\left( x_{i}, a_{- i} \right) \geq u_{i}\left( a_{i},a_{- i} \right)$</span> for every list <span>$a_{- i}$</span> of the other players’ actions and <span>$U_{i}\left( x_{i},a_{- i} \right) &gt; u_{i}(a_{i},a_{- i})$</span> for some list <span>$a_{- i}$</span> of the other players’ actions. A weakly dominated action may be used in a Nash equilibrium. Thus, a weakly dominated action may be used with positive probability in a mixed strategy equilibrium, so that we cannot eliminate weakly dominated actions from consideration when finding mixed strategy equilibria!</p><p>Nash’s Existence Theorem: Every finite strategic game must have at least one Nash equilibrium if we allow mixed strategies. A game is finite if it has finitely many players and finitely many actions for each player.</p><p>Best response functions:</p><p>The best response function is a set valued function that takes actions which all other players have chosen for the game (mixed or pure) and returns the best possible set of responses for player <span>$\text{i}$</span>(mixed or pure). In a Nash equilibrium, everyone plays a best response.</p><h3>Solving for Nash equilibrium</h3><ol><li><p>First, solve for <em>pure strategy</em> equilibria</p><ul><li><p>Elimination of strictly dominated strategies</p></li><li><p>Best response functions: In a Nash Equilibrium, the players play their   best responses to one another’s strategies. To find these best   responses:</p><ul><li><p>If payoffs are differentiable, you are free to use calculus. You can   take the derivative of the payoff function with respect to your own   action (which is on some interval), given the fixed actions of other   players. Set this value to zero, and ensure that you have a global   maximum (can be done by taking the second derivative, and comparing   to other critical points).</p></li><li><p>If the best response function outputs are discrete or   non-differentiable, just find where the best response function   outputs (which are set valued) intersect.</p></li><li><p>If the game can be displayed in a simple table, then the best   responses for both players can just be highlighted in their   respective cells.</p></li></ul></li></ul></li><li><p>Then find all <em>mixed strategy</em> Nash equilibria:</p><ul><li><p>Elimination of strictly dominated strategies:</p><ul><li><p>Try to find a mix of two or more strategies that dominate a third   strategy</p></li></ul></li><li><p>If a mixed strategy is a best response, then each of the pure   strategies involved in the mix must themselves be a best response. In   other words, if the best response to your opponent’s action involves   mixed strategy, then every pure strategy in the mix is a best response.   You are indifferent between your pure and mixed strategies.</p><ul><li><p>Proof: If a mixed strategy is a best response, then each of the   pure strategies involved in the mix must themselves be a best   response.  Each must yield the same expected payoff. Why is this   true? Suppose it were not true. Then there must be at least one   pure strategy that is assigned positive probability by the   best-response mix and that yields a lower expected payoff. If there   is more than one, focus on the one that yields the lowest expected   payoff. Suppose that (low-yield) pure strategy from the mix is   dropped, assigning the weight used to one of the other   (higher-yield) strategies in the mix. This must raise the expected   payoff (just as dropping the player with the lowest batting average   on a team must raise the team average). But then the original mixed   strategy cannot have been a best response: it does not do as well   as the new mixed strategy.  This is a contradiction.</p></li></ul></li><li><p>The expected payoff in a mixed strategy Nash equilibrium must be the   same as the expected payoffs of all pure actions in that mixed   strategy.  Otherwise, then if the expected value of one action is   higher, the player can place a higher probability onto that action and   deviate for a higher payoff. Stated another way, if the expected   payoffs are the same across all actions in a mixed strategy Nash   equilibrium for player x, then this means that to achieve a mixed   strategy Nash equilibrium, player y must play his or her actions in a   mix such that player x is indifferent between any of his or her pure   strategies that he or she would use in a mix.</p></li><li><p>If a player does not use an action in a mixed strategy Nash   equilibrium, then the expected payoff of this pure strategy must be no   greater than the expected payoff of any of the pure strategies the   player does use in a mixed strategy equilibrium.</p></li><li><p>Overall, in two by two games, the players in a mixed strategy Nash   equilibrium are indifferent not only between their pure strategies, but   also between any mix or combination of their pure strategies.</p></li></ul></li></ol><h3>Rendezvous Problem</h3><p>Two people agreed to meet at a park which neither has been to. When they arrive, they discover that the park is huge and they have no way of finding each other.  What strategy can they both adopt to ensure that they meet, and what is the minimum time that they can find each other by using such a strategy?</p><p>Stated more formally:</p><p>Two players start at a distance of 2 on an (undirected) line (so, neither player knows the direction of the other) and both move at a maximum speed of 1. What is the infimum expected meeting time R (first time when the players occupy the same point) which can be achieved assuming the two players must adopt the same strategy?</p><h3>Other Fun Problems</h3><p><a href="http://fivethirtyeight.com/features/can-you-solve-the-puzzle-of-the-pirate-booty/">Gold and Pirates (Thanks Matthew, for the suggestion!)</a></p><p>The Two Envelope Problem (Thanks Greg, for the demonstration of this problem!)<a href="#footnote-1">[1]</a></p><div id="footnote-1" class="footnote"><a href="#footnote-1"><strong>[1]</strong></a><p>Sorry for the Wikipedia link, but I couldn’t find a more complete</p></div><p>description of the problem! Skip to the section on randomized problems and the solution Greg showed in the session is provided there.</p><h3>Sources / Further Reading</h3><p>Extensive form games:</p><ul><li><p>http://web.stanford.edu/~jdlevin/Econ%20203/ExtensiveForm.pdf</p></li><li><p>http://academics.hamilton.edu/economics/cgeorges/game-theory-files/Notation-Definitions.pdf</p></li><li><p>http://oyc.yale.edu/sites/default/files/mixed_strategies_handout_0.pdf</p></li><li><p>http://www.inf.ed.ac.uk/teaching/courses/agta/lec2.pdf</p></li><li><p>http://pioneer.netserv.chula.ac.th/~ptanapo1/gamebook.pdf</p></li><li><p>http://homepages.cwi.nl/~apt/stra/ch10.pdf</p></li><li><p>http://www.openproblemgarden.org/op/rendezvous_on_a_line</p></li><li><p>https://www.macalester.edu/~abeverid/papers/rendezvous-line.pdf</p></li><li><p>http://www.cdam.lse.ac.uk/Reports/Files/cdam-2007-05.pdf</p></li><li><p>http://www.optimization-online.org/DB_FILE/2006/05/1400.pdf</p></li></ul></div><h2>Tags</h2><ul><li><a class="tag-link tag-economics" href="/tag/economics">economics</a></li><li><a class="tag-link tag-game-theory" href="/tag/game-theory">game theory</a></li></ul></article></section></body></html>
