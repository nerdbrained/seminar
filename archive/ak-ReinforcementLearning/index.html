<!DOCTYPE html>
<html><head><meta charset="utf-8" /><meta name="google-site-verification" content="NaytRH7PCHM8SH9XV-xgMLEi_1m1wS9lPBAIvTJ-wvs" /><link href="//yegor256.github.io/tacit/tacit.min.css" rel="stylesheet" /><link href="/css/custom.css" rel="stylesheet" /><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-93527069-1', 'auto');
ga('send', 'pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    jax: [
        "input/TeX",
        "input/MathML",
        "input/AsciiMath",
        "output/CommonHTML"
    ],
    extensions: [
        "tex2jax.js",
        "mml2jax.js",
        "asciimath2jax.js",
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js"
    ],
    TeX: {
        extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js"
        ]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": {
        availableFonts: ["TeX"]
    }
});
</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script><title>Reinforcement Learning in Games</title></head><body><nav><ul><li><a href="/"><img src="/images/logo.png" height="64" title="Home" alt="Home" width="64" /></a></li><li><a href="/archive">archive</a></li><li><a href="/tags">tags</a></li><li><a href="/faq">faq</a></li><li><a href="/document">library</a></li><li><a href="/potential-topics">topics</a></li><li><a href="/submit-talk">speak</a></li></ul></nav><section><article><p>This talk on Reinforcement Learning in Games was held on Friday October 21, 2016 in MC 4020. The speaker was Agastya Kalra.</p><h2>Abstract</h2><div><h2>Outline</h2><ul><li><p>What is supervised machine learning? </p></li><li><p>What is the reinforcement learning problem?</p></li><li><p>Examples:   Deepmind Atari,    Alpha GO,    TD Gammon </p></li><li><p>Basic Q Learning interactive intuition based on human brain </p></li><li><p>Formalizing Q Learning </p></li><li><p>Lets set up a problem </p></li><li><p>Scaling Q Learning interactive intuition </p></li><li><p>Improvements (if we get this far)  Double Q Intuition,   Experience Replay,   Frozen Model,   Prioritized Replay </p></li></ul></div><h2>Tags</h2><ul><li><a class="tag-link tag-computer-science" href="/tag/computer-science">computer science</a></li><li><a class="tag-link tag-machine-learning" href="/tag/machine-learning">machine learning</a></li><li><a class="tag-link tag-optimization" href="/tag/optimization">optimization</a></li></ul></article></section></body></html>
