<!DOCTYPE html>
<html><head><meta charset="utf-8" /><meta content="NaytRH7PCHM8SH9XV-xgMLEi_1m1wS9lPBAIvTJ-wvs" name="google-site-verification" /><link rel="stylesheet" href="//yegor256.github.io/tacit/tacit.min.css" /><link rel="stylesheet" href="/css/custom.css" /><script type="text/x-mathjax-config">MathJax.Hub.Config({
    jax: [
        "input/TeX",
        "input/MathML",
        "input/AsciiMath",
        "output/CommonHTML"
    ],
    extensions: [
        "tex2jax.js",
        "mml2jax.js",
        "asciimath2jax.js",
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js"
    ],
    TeX: {
        extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js"
        ]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": {
        availableFonts: ["TeX"]
    }
});
</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script><title>Reinforcement Learning in Games</title></head><body><nav><ul><li><a href="/">Math Seminar Home</a></li><li><a href="/archive">archive</a></li><li><a href="/tags">tags</a></li><li><a href="/faq">faq</a></li><li><a href="/document">library</a></li><li><a href="/potential-topics">topics</a></li><li><a href="/submit-talk">speak</a></li></ul></nav><section><article><p>This talk on Reinforcement Learning in Games was held on Friday October 21, 2016 in MC 4020. The speaker was Agastya Kalra.</p><h2>Abstract</h2><div class="markdown"><h3>Outline</h3>
<ul>
<li><p>What is supervised machine learning? </p>
</li>
<li><p>What is the reinforcement learning problem?</p>
</li>
<li><p>Examples:   Deepmind Atari,    Alpha GO,    TD Gammon </p>
</li>
<li><p>Basic Q Learning interactive intuition based on human brain </p>
</li>
<li><p>Formalizing Q Learning </p>
</li>
<li><p>Lets set up a problem </p>
</li>
<li><p>Scaling Q Learning interactive intuition </p>
</li>
<li><p>Improvements &#40;if we get this far&#41;  Double Q Intuition,   Experience Replay,   Frozen Model,   Prioritized Replay </p>
</li>
</ul>
</div><h2>Tags</h2><ul><li><a href="/tag/computer-science" class="tag-link tag-computer-science">computer-science</a></li><li><a href="/tag/first-year-friendly" class="tag-link tag-first-year-friendly">first-year-friendly</a></li><li><a href="/tag/machine-learning" class="tag-link tag-machine-learning">machine-learning</a></li><li><a href="/tag/optimization" class="tag-link tag-optimization">optimization</a></li></ul></article></section></body></html>
