<!DOCTYPE html>
<html><head><meta charset="utf-8" /><meta name="google-site-verification" content="NaytRH7PCHM8SH9XV-xgMLEi_1m1wS9lPBAIvTJ-wvs" /><link href="//yegor256.github.io/tacit/tacit.min.css" rel="stylesheet" /><link href="/css/custom.css" rel="stylesheet" /><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-93527069-1', 'auto');
ga('send', 'pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    jax: [
        "input/TeX",
        "input/MathML",
        "input/AsciiMath",
        "output/CommonHTML"
    ],
    extensions: [
        "tex2jax.js",
        "mml2jax.js",
        "asciimath2jax.js",
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js"
    ],
    TeX: {
        extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js"
        ]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": {
        availableFonts: ["TeX"]
    }
});
</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script><title>Convex Optimization</title></head><body><nav><ul><li><a href="/"><img src="/images/logo.png" height="64" title="Home" alt="Home" width="64" /></a></li><li><a href="/archive">archive</a></li><li><a href="/tags">tags</a></li><li><a href="/faq">faq</a></li><li><a href="/document">library</a></li><li><a href="/potential-topics">topics</a></li></ul></nav><section><article><p>This talk on Convex Optimization was held on Friday October 28, 2016 in MC 4020. The speaker was Rolina Wu.</p><h2>Abstract</h2><div><p>This talk will introduce the basics for Convex Optimization, several popular optimization algorithms, and the application for convex optimization in Machine Learning.</p><p><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Boyd and Vandenberghe, 2004</a> will be used for reference.</p><h2>Outline</h2><ul><li><p>Introduction(definition of Affine, Convex Sets, Convex functions, Conic Combinations, Convex Cones, and Convex Hulls)</p><ul><li><p>The main focus will be on Affine, Convex functions, Convex and Conic hulls. </p></li></ul></li><li><p>Extreme points</p></li><li><p>Subdifferentials</p></li><li><p>Convex Minimization + Maximization</p></li><li><p>Applications: </p><ul><li><p>Perceptron</p></li><li><p>Gradient Descent</p><ul><li><p>How it is used in Machine Learning algorithms</p></li></ul></li></ul></li></ul></div><h2>Tags</h2><ul><li><a class="tag-link tag-gradient-descent" href="/tag/gradient-descent">gradient descent</a></li><li><a class="tag-link tag-machine-learning" href="/tag/machine-learning">machine learning</a></li><li><a class="tag-link tag-optimization" href="/tag/optimization">optimization</a></li></ul></article></section></body></html>
