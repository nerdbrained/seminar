<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"/><meta name="google-site-verification" content="NaytRH7PCHM8SH9XV-xgMLEi_1m1wS9lPBAIvTJ-wvs"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="//wumss.github.io/rabbit/rabbit.min.css"/><link rel="stylesheet" href="/css/custom.css"/><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-93527069-1', 'auto');
ga('send', 'pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    jax: [
        "input/TeX",
        "input/MathML",
        "input/AsciiMath",
        "output/CommonHTML"
    ],
    extensions: [
        "tex2jax.js",
        "mml2jax.js",
        "asciimath2jax.js",
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js"
    ],
    TeX: {
        extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js"
        ]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": {
        availableFonts: ["TeX"]
    }
});
</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script><title>Algorithm</title></head><body><header><nav><input id="nav-trigger" class="nav-trigger" type="checkbox" checked="checked"/><ul><li><a href="/"><img src="/images/logo.png" height="64" width="64" alt="Home" title="Home"/></a></li><li><a href="/submit-talk/">present</a></li><li><a href="/archive/">archive</a></li><li><a href="/tag/">tags</a></li><li><a href="/faq/">faq</a></li><li><a href="/document/">library</a></li><li><a href="/potential-topics/">topics</a></li></ul><label for="nav-trigger"></label></nav></header><main><article><h1>Algorithm</h1><p>There have been 3 completed talks and 5 topic suggestions tagged with <b>algorithm</b>.</p><h2>Related Tags</h2><ul><li><a class="tag-link tag-probability" href="/tag/probability/">probability</a></li><li><a class="tag-link tag-bloom-filter" href="/tag/bloom-filter/">bloom filter</a></li><li><a class="tag-link tag-space-efficiency" href="/tag/space-efficiency/">space efficiency</a></li><li><a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a></li><li><a class="tag-link tag-data-structure" href="/tag/data-structure/">data structure</a></li><li><a class="tag-link tag-computational-mathematics" href="/tag/computational-mathematics/">computational mathematics</a></li><li><a class="tag-link tag-optimization" href="/tag/optimization/">optimization</a></li><li><a class="tag-link tag-cryptography" href="/tag/cryptography/">cryptography</a></li></ul><h2>Completed Talks</h2><h3><a href="/archive/fb-stable">A 3/2-approximation algorithm for the stable marriage problem with ties</a></h3><p>Delivered by Felix Bauckholt on Wednesday October 4, 2017</p><p>I will introduce the Stable Marriage Problem, and its NP-complete cousin, the Stable Marriage Problem with ties. I will present a simplified version of Király’s 3/2-approximation algorithm, which archieves the best approximation ratio known.</p><p>The <a href="/assets/stable-marriage-approximation.pdf">slides for this presentation</a> are available.</p><h3><a href="/archive/fr-MEDR">Metric embeddings and dimensionality reduction</a></h3><p>Delivered by Frieda Rong on Friday March 31, 2017</p><p>In this talk, we consider embeddings which preserve the pairwise distances of a set of points.  It is often useful to find mappings from one high dimensional space to a lower dimensional space that preserve the geometry of the points. One source of applications is in streaming large amounts of data, for which storage is costly and/or impractical. However, the study of such embeddings has also inspired developments in the design of approximation algorithms and compressed sensing.</p><p>At the crux of the talk is the remarkable Johnson-Lindenstrauss lemma. This fundamental result shows that for Euclidean spaces, it is possible to achieve significant dimensionality reduction of a set of points while approximately preserving the pairwise distances. An elementary proof will be given, along  with subsequent speed improvements with sparse projections and an interesting use of the Fourier transform. We will also discuss applications of the lemma to the fields mentioned above.</p><h3><a href="/archive/lm-BF">Bloom Filters and Other Probabilistic Data Structures</a></h3><p>Delivered by Luthfi Mawarid on Friday March 3, 2017</p><p>With the advent of big data, the ability to process large volumes of data is becoming increasingly important. For instance, when dealing with large data sets, we may want to perform simple operations such as counting the number of unique elements or checking whether or not an element is present in the set. While there are deterministic data structures, such as hash tables, that can perform these quickly, the sheer size of the data involved makes their use largely  impractical and unscalable.Instead, we may want to trade-off some accuracy in our  answers in exchange for greater space efficiency and ease of parallelization.  For this, we introduce the concept of probabilistic data structures. </p><p>In this talk, we will mainly focus on Bloom filters, which are commonly used to test set membership and speed up data access. We will explore its main use cases, its implementation details, and the mathematics behind it. If time permits, I will also talk about the count min-sketch, used for frequency counting, and/or the HyperLogLog counter, used for cardinality estimation.</p><p>This talk will assume basic knowledge of probability.</p><h2 id="suggestions">Talk Suggestions</h2><h3>Complexity of Matrix Multiplication</h3><div><p>Volker Strassen showed that <span>$n^3$</span> matrix multiplication was not optimal in 1969. Since then, new algorithms such as Coppersmith-Winograd have further improved the time complexity of matrix multiplication. It is conjectured that matrix multiplication is possible in <span>$O(n^{2+ɛ})$</span> for any <span>$ɛ&gt;0$</span>, however small. This is one of the few remaining open problems in finite-dimensional linear algebra.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="http://www.cs.umd.edu/~gasarch/TOPICS/ramsey/matrixmult.pdf">Don Coppersmith and Shmuel Winograd</a></p></div></li><li><div><p><a href="http://ieeexplore.ieee.org/document/1530730/?section=abstract&amp;part=1">H. Cohn, R. Kleinberg, B. Szegedy and C. Umans, &quot;Group-theoretic algorithms for matrix multiplication,&quot; 46th Annual IEEE Symposium on Foundations of Computer Science (FOCS&#39;05), 2005, pp. 379-388. doi: 10.1109/SFCS.2005.39</a></p></div></li><li><div><p><a href="http://www.maths.ed.ac.uk/sites/default/files/atoms/files/stothers.pdf">Andrew James Stothers, On The Complexity of Matrix Multiplication</a></p></div></li><li><div><p><a href="https://galton.uchicago.edu/mart/slides/Umans-talk-1.pdf">Chris Umans, Approaches to bounding the exponent of matrix multiplication</a></p></div></li><li><div><p><a href="https://www.ma.utexas.edu/users/horem/gtpmm.pdf">Richard Strong Bowen, Bob Chen, Hendrik Orem, and Martijn van Schaardenburg: Group-Theoretic Partial Matrix Multiplication</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Complexity of Matrix Multiplication" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Complexity of Matrix Multiplication" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-algebra" href="/tag/algebra/">algebra</a> <a class="tag-link tag-algorithm" href="/tag/algorithm/">algorithm</a> <a class="tag-link tag-computational-mathematics" href="/tag/computational-mathematics/">computational mathematics</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-group-theory" href="/tag/group-theory/">group theory</a> <a class="tag-link tag-linear-algebra" href="/tag/linear-algebra/">linear algebra</a> <a class="tag-link tag-open-problem" href="/tag/open-problem/">open problem</a> </p><h3>Galois Field Arithmetic</h3><div><p>A Galois field is a finite field and are used in a variety of applications, including in classical coding theory and cryptography algorithms. This topic studies how to efficiently optimize arithmetic in such fields.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="http://web.eecs.utk.edu/~plank/plank/papers/FAST-2013-GF.html">Plank, Greenan, Miller</a></p></div></li><li><div><p><a href="https://www.math.washington.edu/~morrow/336_12/papers/juan.pdf">Christoforus Juan Benvenuto</a></p></div></li><li><div><p><a href="http://www.springer.com/?SGWID=4-102-45-110359-0">Finite Field Arithmetic</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Galois Field Arithmetic" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Galois Field Arithmetic" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-algebra" href="/tag/algebra/">algebra</a> <a class="tag-link tag-algorithm" href="/tag/algorithm/">algorithm</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-cryptography" href="/tag/cryptography/">cryptography</a> <a class="tag-link tag-efficiency" href="/tag/efficiency/">efficiency</a> <a class="tag-link tag-field-theory" href="/tag/field-theory/">field theory</a> </p><h3>Gillespie Algorithm</h3><div><p>The Gillespie Algorithm for stochastic equations is used heavily in a number of fields of applied mathematics, in particular computational systems biology.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="https://www.cs.princeton.edu/picasso/seminarsS05/Karig_slides.pdf">David Karig</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Gillespie Algorithm" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Gillespie Algorithm" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-algorithm" href="/tag/algorithm/">algorithm</a> <a class="tag-link tag-applied-mathematics" href="/tag/applied-mathematics/">applied mathematics</a> <a class="tag-link tag-biology" href="/tag/biology/">biology</a> <a class="tag-link tag-computational-biology" href="/tag/computational-biology/">computational biology</a> <a class="tag-link tag-computational-mathematics" href="/tag/computational-mathematics/">computational mathematics</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-differential-equation" href="/tag/differential-equation/">differential equation</a> <a class="tag-link tag-probability" href="/tag/probability/">probability</a> <a class="tag-link tag-stochastic-equation" href="/tag/stochastic-equation/">stochastic equation</a> </p><h3>The Joy of Factoring</h3><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="https://books.google.ca/books/about/The_Joy_of_Factoring.html?id=rowCAQAAQBAJ&amp;redir_esc=y">Samuel S. Wagstaff (Jr.)</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=The Joy of Factoring" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=The Joy of Factoring" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-algorithm" href="/tag/algorithm/">algorithm</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-cryptography" href="/tag/cryptography/">cryptography</a> <a class="tag-link tag-number-theory" href="/tag/number-theory/">number theory</a> <a class="tag-link tag-quantum-algorithm" href="/tag/quantum-algorithm/">quantum algorithm</a> </p><h3>Wilf zeilberg method to computer verify combinatorial identities</h3><div><p>One of the most exciting mathematical discoveries in the early 1990s was the Wilf-Zeilberger (WZ) algorithm that can be used for proving, evaluating, and discovering identities involving hypergeometric terms automatically by computer. And unlike computerized proof techniques in other areas, the computerized proofs generated by this method provides a <em>certificate</em> for the validity of a combinatorial identity, called a <em>WZ-pair</em>.</p><p><strong>Required Background</strong>: Combinatorics at the level of Math 249, Calculus at the level of Math 147.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.306.5080&amp;rep=rep1&amp;type=pdf">Wilf, Zeilberger</a></p></div></li><li><div><p><a href="https://www.math.upenn.edu/~wilf/Downld.html">Wilf, Zeilberger, Petkovsek</a></p></div></li><li><div><p><a href="http://www.ams.org/notices/201004/rtx100400508p.pdf">Akalu Tefera</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Wilf zeilberg method to computer verify combinatorial identities" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Wilf zeilberg method to computer verify combinatorial identities" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-algorithm" href="/tag/algorithm/">algorithm</a> <a class="tag-link tag-combinatorics" href="/tag/combinatorics/">combinatorics</a> <a class="tag-link tag-computer-algebra" href="/tag/computer-algebra/">computer algebra</a> </p></article><footer><p>Help improve this page by <a href="https://github.com/wumss/seminar/edit/master/wiki/tag/algorithm.md">editing it on GitHub</a>.</p></footer></main></body></html>
