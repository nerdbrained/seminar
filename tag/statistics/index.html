<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"/><meta name="google-site-verification" content="NaytRH7PCHM8SH9XV-xgMLEi_1m1wS9lPBAIvTJ-wvs"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="//yegor256.github.io/tacit/tacit.min.css"/><link rel="stylesheet" href="/css/custom.css"/><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-93527069-1', 'auto');
ga('send', 'pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    jax: [
        "input/TeX",
        "input/MathML",
        "input/AsciiMath",
        "output/CommonHTML"
    ],
    extensions: [
        "tex2jax.js",
        "mml2jax.js",
        "asciimath2jax.js",
        "MathMenu.js",
        "MathZoom.js",
        "AssistiveMML.js"
    ],
    TeX: {
        extensions: [
            "AMSmath.js",
            "AMSsymbols.js",
            "noErrors.js",
            "noUndefined.js"
        ]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": {
        availableFonts: ["TeX"]
    }
});
</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script><title>Statistics</title></head><body><nav><input id="nav-trigger" class="nav-trigger" type="checkbox" checked="checked"/><ul><li><a href="/"><img src="/images/logo.png" height="64" width="64" alt="Home" title="Home"/></a></li><li><a href="/archive">archive</a></li><li><a href="/tags">tags</a></li><li><a href="/faq">faq</a></li><li><a href="/document">library</a></li><li><a href="/potential-topics">topics</a></li></ul><label for="nav-trigger"></label></nav><section><article><h1>Statistics</h1><p>There have been 1 completed talk and 7 topic suggestions tagged with <b>statistics</b>.</p><p>There are many subfields of <b>statistics</b>, including: </p><ul><li><a class="tag-link tag-data-science" href="/tag/data-science/">data science</a></li><li><a class="tag-link tag-information-theory" href="/tag/information-theory/">information theory</a></li></ul><h2>Related Tags</h2><ul><li><a class="tag-link tag-data-science" href="/tag/data-science/">data science</a></li><li><a class="tag-link tag-information-theory" href="/tag/information-theory/">information theory</a></li><li><a class="tag-link tag-probability" href="/tag/probability/">probability</a></li><li><a class="tag-link tag-tech-talks" href="/tag/tech-talks/">Tech Talks</a></li><li><a class="tag-link tag-approximation" href="/tag/approximation/">approximation</a></li><li><a class="tag-link tag-tutorial" href="/tag/tutorial/">tutorial</a></li><li><a class="tag-link tag-kolmogorov-complexity" href="/tag/kolmogorov-complexity/">Kolmogorov complexity</a></li><li><a class="tag-link tag-parallel-computing" href="/tag/parallel-computing/">parallel computing</a></li></ul><h2>Completed Talks</h2><h3><a href="/archive/ss-Information">Information Theory</a></h3><p>Delivered by Sidhant Saraogi on Friday October 14, 2016</p><p>I will try to provide a brief introduction to Information Theory working towards motivating Shannon&#39;s Source Coding Theorem. We will use rather simple examples (for e.g. Repetition Codes) to explain the idea of noisy channels and  similarly simple examples to explain the idea behind the theorem and  eventually try to prove it for a rather specific example. (if we have the time !)</p><h2 id="suggestions">Talk Suggestions</h2><h3>Complex Event Processing Systems</h3><div><p>The ever-increasing amount of information that needs to be processed has led to the development of Complex Event Processing systems such as Apache Storm or Twitter Heron. These systems distribute a workload over many machines in a cluster, and offer both efficiency and fault-tolerance.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="https://storm.apache.org">Apache Storm</a></p></div></li><li><div><p>Kulkarni, S., Bhagat, N., Fu, M., Kedigehalli, V., Kellogg, C., Mittal, S., ... &amp; Taneja, S. (2015, May). Twitter heron: Stream processing at scale. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data (pp. 239-250). ACM. doi:10.1145/2723372.2742788</p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Complex Event Processing Systems" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Complex Event Processing Systems" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-tech-talks" href="/tag/tech-talks/">Tech Talks</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-data-science" href="/tag/data-science/">data science</a> <a class="tag-link tag-distributed-system" href="/tag/distributed-system/">distributed system</a> <a class="tag-link tag-first-year-friendly" href="/tag/first-year-friendly/">first year friendly</a> <a class="tag-link tag-parallel-computing" href="/tag/parallel-computing/">parallel computing</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> </p><h3>Dealing with Missing Data</h3><div><p>Data are rarely perfect. Robust data science tools must have ways to deal with missing data. However, this is not always easy. A balance must be struck between performance and convenience.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="https://en.wikipedia.org/wiki/Missing_data">Wikipedia</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Dealing with Missing Data" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Dealing with Missing Data" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-tech-talks" href="/tag/tech-talks/">Tech Talks</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-data-science" href="/tag/data-science/">data science</a> <a class="tag-link tag-efficiency" href="/tag/efficiency/">efficiency</a> <a class="tag-link tag-first-year-friendly" href="/tag/first-year-friendly/">first year friendly</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> </p><h3>Entropy in Mathematics and Information Theory</h3><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="https://ee.stanford.edu/~gray/it.pdf">Robert M. Gray</a></p></div></li><li><div><p><a href="http://astarte.csustan.edu/~tom/SFI-CSSS/info-theory/info-lec.pdf">Tom Carter</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Entropy in Mathematics and Information Theory" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Entropy in Mathematics and Information Theory" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-information-theory" href="/tag/information-theory/">information theory</a> <a class="tag-link tag-probability" href="/tag/probability/">probability</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> </p><h3>Fermi Estimation</h3><div><p>Physicist Enrico Fermi was known for his impressive order-of-magnitude estimation. He was famously able to estimate the yield of the Trinity test atomic bomb to about a factor of two. Why is Fermi estimation so useful and accurate? What are the techniques to make better approximations? How can and do scientists, mathematicians, engineers, and others use Fermi estimation in their work?</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="http://web.mit.edu/6.055/">Art of approximation in science and engineering</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Fermi Estimation" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Fermi Estimation" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-approximation" href="/tag/approximation/">approximation</a> <a class="tag-link tag-physics" href="/tag/physics/">physics</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> </p><h3>Jupyter Notebooks</h3><div><p>Jupyter Notebooks are a must-have for any data scientist or engineer. They are available for a wide variety of programming languages, particularly Python.</p></div><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="http://jupyter.org/">Project Jupyter</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Jupyter Notebooks" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Jupyter Notebooks" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-tech-talks" href="/tag/tech-talks/">Tech Talks</a> <a class="tag-link tag-data-science" href="/tag/data-science/">data science</a> <a class="tag-link tag-first-year-friendly" href="/tag/first-year-friendly/">first year friendly</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> <a class="tag-link tag-tutorial" href="/tag/tutorial/">tutorial</a> </p><h3>Kolmogorov complexity</h3><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="http://homepages.cwi.nl/~paulv/course-kc/KC-Lecture1.pdf">Paul Vitanyi</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Kolmogorov complexity" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Kolmogorov complexity" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-kolmogorov-complexity" href="/tag/kolmogorov-complexity/">Kolmogorov complexity</a> <a class="tag-link tag-computer-science" href="/tag/computer-science/">computer science</a> <a class="tag-link tag-information-theory" href="/tag/information-theory/">information theory</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> <a class="tag-link tag-theoretical-computer-science" href="/tag/theoretical-computer-science/">theoretical computer science</a> </p><h3>Optimal Stopping Theory and the Secretary Problem</h3><p>Possible reference materials for this topic include</p><ul><li><div><p><a href="https://www.math.upenn.edu/~ted/210F10/References/Secretary.pdf">Thomas S. Ferguson</a></p></div></li><li><div><p><a href="http://theory.stanford.edu/~sergei/slides/hiring-dagstuhl.pdf">Sergei Vassilvitski</a></p></div></li></ul><p>Quick links: <a href="https://www.google.ca/search?q=Optimal Stopping Theory and the Secretary Problem" rel="nofollow">Google search</a>, <a href="http://search.arxiv.org:8081/?query=Optimal Stopping Theory and the Secretary Problem" rel="nofollow">arXiv.org search</a>, <a href="/submit-talk">propose to present a talk</a></p><p><a class="tag-link tag-decision-theory" href="/tag/decision-theory/">decision theory</a> <a class="tag-link tag-probability" href="/tag/probability/">probability</a> <a class="tag-link tag-statistics" href="/tag/statistics/">statistics</a> </p></article><footer><p>Help improve this page by <a href="https://github.com/wumss/seminar/edit/master/wiki/tag/Remarkable.Tags.Tag(&quot;statistics&quot;).md">editing it on GitHub</a>.</p></footer></section></body></html>
